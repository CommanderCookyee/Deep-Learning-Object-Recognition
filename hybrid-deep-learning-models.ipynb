{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport requests\nimport os\nimport random\nimport pickle\nimport matplotlib.pyplot as plt\nimport tensorflow as jf\nfrom tensorflow.keras import layers\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.python.keras import backend as K\nimport pathlib\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom skimage.filters import gabor\nfrom skimage.filters import gabor_kernel\n# importing Dependencies\n\nimport os\nimport glob\nimport pandas as pd \n\n\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom tensorflow.keras import layers\nimport tensorflow.keras as keras\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Input, Dropout, concatenate,Conv2D,MaxPooling2D, Flatten,Dense,BatchNormalization\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nfrom skimage.feature import greycomatrix, greycoprops\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications import NASNetLarge\nimport os\nimport numpy as np\nfrom PIL import Image\nimport cv2\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nSIZE = 256\nBATCH_SIZE = 15\nTARGET_SIZE = (SIZE,SIZE)\n# Set the directory path where your images are stored\ndir_path = '/kaggle/input/v5minor100/V5Minor100'\n\n# Loop through the directory and load each image\n# for folder in os.listdir(dir_path):\n#     print(folder)\n#     for img in os.listdir(os.path.join(dir_path, folder)):\n#         # Open the image\n        \n#         img = dir_path + folder + \"/\" + img\n#         img = Image.open(img)\n#         img = img.resize(TARGET_SIZE)\n#         img = np.array(img)\n#         # Append the image to the images list\n#         images.append(img)\n#         # Append the label to the labels list\n#         labels.append(folder)\n        \n        \n        \n# Create empty lists to store the images and labels\nimages = []\nlabels = []\ncount = 0 \ncnt = 0 \n# Loop through the directory and load each image\nfor folder in os.listdir(dir_path):\n    print(folder)\n    for img in os.listdir(os.path.join(dir_path, folder)):\n        if count == 5:\n            folder = \"Natural\"\n\n        if cnt == 10:\n            break\n        # Open the image\n        try: \n            img = \"/kaggle/input/v5minor100/V5Minor100/\" + folder + \"/\" + img\n\n            image = cv2.imread(img, 3)\n            image = cv2.resize(image, TARGET_SIZE)\n            # Append the image to the images list\n            image = np.array(image)\n            images.append(image)\n            # Append the label to the labels list\n            labels.append(folder)\n            count += 1\n            cnt += 1\n            print(count)\n            print(cnt)\n\n        except:\n            pass\n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into a train and test set\nX_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\nprint(len(X_train))\nprint(len(X_val))\nprint(len(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import skimage\nfrom scipy import ndimage\nimport numpy as np\nfrom skimage.measure import shannon_entropy\nfrom scipy.stats import entropy\nfrom skimage import io, color, feature, measure\n# Set the Gabor filter parameters\n\n\ndef feature_extractor(images):\n    image_dataset = pd.DataFrame()\n    for img in images:   \n        dists = [1]\n        angles = [0]\n        \n        \n        df = pd.DataFrame()\n        # Extract GLCM features for R channel\n        glcm_r = skimage.feature.graycomatrix(img[:, :, 0], dists, angles, 256, symmetric=True, normed=True)\n        # Extract GLCM features for G channel\n        glcm_g = skimage.feature.graycomatrix(img[:, :, 1],dists,  angles, 256, symmetric=True, normed=True)\n        # Extract GLCM features for B channel\n        glcm_b = skimage.feature.graycomatrix(img[:, :, 2], dists,  angles, 256, symmetric=True, normed=True)\n        # Extract GLCM features for RG channel\n        img_rg = np.zeros((img.shape[0], img.shape[1], 2))\n        img_rg[:, :, 0] = img[:, :, 0]\n        img_rg[:, :, 1] = img[:, :, 1]\n        img_rg_8bit = img_rg[:,:,1].astype(np.uint8)\n        glcm_rg = skimage.feature.graycomatrix(img_rg_8bit, dists,  angles, 256, symmetric=True, normed=True)\n        # Extract GLCM features for RB channel\n        img_rb = np.zeros((img.shape[0], img.shape[1], 2))\n        img_rb[:, :, 0] = img[:, :, 0]\n        img_rb[:, :, 1] = img[:, :, 2]\n        img_rb_8bit = img_rb[:,:,1].astype(np.uint8)\n        glcm_rb = skimage.feature.graycomatrix(img_rb_8bit, dists,  angles, 256, symmetric=True, normed=True)\n        # Extract GLCM features for GB channel\n        img_gb = np.zeros((img.shape[0], img.shape[1], 2))\n        img_gb[:, :, 0] = img[:, :, 1]\n        img_gb[:, :, 1] = img[:, :, 2]\n        img_gb_8bit = img_gb[:,:,1].astype(np.uint8)\n        glcm_gb = skimage.feature.graycomatrix(img_gb_8bit, dists,  angles, 256, symmetric=True, normed=True)\n        \n#         for j, color in enumerate(['r', 'g', 'b']):\n#             hist = skimage.exposure.histogram(img[:, :, j], nbins=256)\n            \n#             df[f'hist_{color}'] = [hist[0].var()]\n\n\n\n\n#             cb = skimage.measure.shannon_entropy(hist)\n#             df[f'hist_entropy_{color}'] = [cb]\n\n#         for j, color1 in enumerate(['r', 'g', 'b']):\n#             for k, color2 in enumerate(['r', 'g', 'b']):\n#                 if j < k:\n#                     hist2d, _, _ = np.histogram2d(img[:, :, j].ravel(), img[:, :, k].ravel(), bins=256)\n#                     hist2d /= np.sum(hist2d)\n#                     ca =skimage.measure.shannon_entropy(hist2d.ravel())\n#                     df[f'hist2d_{color1}{color2}_entropy'] = [ca]\n           \n                    \n                    \n# #                 # Set up the Gabor filter parameters\n#         sigmas = (1, 3)\n#         thetas = np.deg2rad([0, 45, 90, 135])\n#         frequencies = (0.05, 0.25)\n#         psis = np.pi/2\n        \n#         # Create a list of Gabor filter kernels for each color channel\n#         kernels = []\n#         for sigma in sigmas:\n#             for theta in thetas:\n#                 for frequency in frequencies:\n#                     kernel = []\n#                     for color in range(3):\n#                         kernel.append(np.real(gabor_kernel(frequency=frequency, theta=theta, sigma_x=sigma, sigma_y=sigma/0.5, n_stds=3)))\n#                     kernels.append(kernel)\n        \n        # Apply each Gabor filter kernel to the image channels and get the mean response\n        for i, kernel in enumerate(kernels):\n            filtered = []\n            for j in range(3):\n                filtered_channel = ndimage.convolve(img[:, :, j], kernel[j], mode='constant', cval=0)\n                filtered.append(filtered_channel)\n            filtered = np.mean(filtered, axis=0)\n            df[f'gabor_{i}'] = [filtered.mean()]\n            print(filtered.mean())\n\n        # Extract the contrast, correlation, energy, and homogeneity properties\n        for i, glcm in enumerate([glcm_r, glcm_g, glcm_b, glcm_rg, glcm_rb, glcm_gb]):\n            df[f'contrast_{i}'] = skimage.feature.graycoprops(glcm, 'contrast')[0]\n            df[f'correlation_{i}'] = skimage.feature.graycoprops(glcm, 'correlation')[0]\n            df[f'energy_{i}'] = skimage.feature.graycoprops(glcm, 'energy')[0]\n            df[f'homogeneity_{i}'] = skimage.feature.graycoprops(glcm, 'homogeneity')[0]\n            df[f'dissimilarity_{i}'] = skimage.feature.graycoprops(glcm, 'dissimilarity')[0]\n            df['Entropy_glcm_r'] = shannon_entropy(img[:, :, 0])\n            df['Entropy_glcm_g'] = shannon_entropy(img[:, :, 1])\n            df['Entropy_glcm_b'] = shannon_entropy(img[:, :, 2])\n            df['Entropy_glcm_rg'] = shannon_entropy(img_rg_8bit)\n            df['Entropy_glcm_gb'] = shannon_entropy(img_gb_8bit)           \n            df['Entropy_glcm_rb'] = shannon_entropy(img_rb_8bit)\n            df['Entropy_glcm_rgb'] = shannon_entropy(img)\n\n\n        image_dataset = image_dataset.append(df, ignore_index=True)\n\n    return image_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_extr_features = feature_extractor(X_train)\ntest_extr_features = feature_extractor(X_test)\nval_extr_features = feature_extractor(X_val)\n#Run to not include GLCM SCM features\n# train_extr_features=train_extr_features.iloc[:,5:11]\n# test_extr_features = test_extr_features.iloc[:,5:11]\n# val_extr_features = val_extr_features.iloc[:,5:11]","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deep_build_mlp():\n    model = keras.Sequential([\n    Dense(128, input_shape=(62,), activation='relu'),\n    Dense(64, activation='relu'),\n    keras.layers.BatchNormalization(),\n    Dense(32, activation='relu'),\n    keras.layers.BatchNormalization(),\n    Dense(16, activation='relu'),\n    keras.layers.BatchNormalization(),\n    Dense(8, activation='relu'),\n    keras.layers.BatchNormalization()   \n    ])\n    print(model.summary())\n    return model\n\ndef build_cnn():\n\n    model = Sequential()\n\n    pretrained_model=tf.keras.applications.resnet.ResNet152(include_top=False,\n                      input_shape=(256,256,3),\n                      pooling='avg',classes=2,\n                      weights='imagenet')\n    for layer in pretrained_model.layers:\n             layer.trainable=True \n\n    model.add(pretrained_model)\n    \n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(8, activation='relu'))\n    return model\n\ndef build_cnn_BASE():\n    model = keras.Sequential([\n        keras.Input(shape=(256,256,3), name='Original_Images'),\n        keras.layers.Conv2D(input_shape=(256,256,3), filters=32, kernel_size=11, \n                            strides=1, activation='relu', name='Conv1'),\n        keras.layers.Conv2D(input_shape=(240,240,32), filters=32, kernel_size=11, \n                            strides=1, activation='relu', name='Conv2'),\n        keras.layers.MaxPool2D(pool_size=(5, 5), strides=2),\n        keras.layers.Conv2D(input_shape=(58,58,32), filters=64, kernel_size=9, \n                            strides=1, activation='relu', name='Conv3'),\n        keras.layers.MaxPool2D(pool_size=(5, 5), strides=2),\n        keras.layers.Conv2D(input_shape=(23,23,64), filters=128, kernel_size=8, \n                            strides=1, activation='relu', name='Conv4'),\n        keras.layers.Conv2D(input_shape=(16,16,128), filters=256, kernel_size=9, \n                            strides=1, activation='relu', name='Conv5'),\n        keras.layers.Conv2D(input_shape=(8,8,256), filters=256, kernel_size=8, \n                            strides=1, activation='relu', name='Conv6'),    \n\n        keras.layers.Flatten(),\n        keras.layers.Dense(8, activation=tf.keras.activations.relu, name='Dense')\n    ])\n    print(model.summary())\n    return model\n\n\ndef build_autoencoder():\n    model = keras.Sequential()\n    input_layer = keras.Input(shape=(62,), name='Input')\n    \n    # Encoder\n    encoded = keras.layers.Dense(128, activation='relu')(input_layer)\n    encoded = keras.layers.BatchNormalization()(encoded)\n    encoded = keras.layers.Dense(64, activation='relu')(encoded)\n    encoded = keras.layers.Dropout(0.2)(encoded)\n    encoded = keras.layers.Dense(32, activation='relu')(encoded)\n    encoded = keras.layers.BatchNormalization()(encoded)\n    \n    # Decoder\n    decoded = keras.layers.Dense(64, activation='relu')(encoded)\n    decoded = keras.layers.BatchNormalization()(decoded)\n    decoded = keras.layers.Dense(128, activation='relu')(decoded)\n    decoded = keras.layers.Dropout(0.2)(decoded)\n    decoded = keras.layers.Dense(62, activation='linear')(decoded)\n    \n    # Define the model\n    model = keras.Model(inputs=input_layer, outputs=decoded)\n    print(model.summary())\n    return model\n\n\ndef build_mlp():\n    model = keras.Sequential([\n        keras.Input(shape=37, name='Extracted_Traditional_Features'),\n        keras.layers.Dense(4, activation=tf.keras.activations.relu, name='Dense1'),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dense(2, activation=tf.keras.activations.relu, name='Dense2'),\n        keras.layers.BatchNormalization()\n    ])\n    print(model.summary())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@title\n#AT = build_autoencoder()\ncnn = build_cnn()\nDMLP = build_autoencoder()\ncombinedInput = concatenate([DMLP.output, cnn.output])\n\nx = Dense(64, activation=\"relu\")(combinedInput)\nkeras.layers.BatchNormalization()(x)\nx = Dropout(0.3)(x)\nx = Dense(32, activation=\"relu\")(x)\nkeras.layers.BatchNormalization()(x)\nx = Dropout(0.27)(x)\nx = Dense(16, activation=\"relu\")(x)\nkeras.layers.BatchNormalization()(x)\nx = Dropout(0.25)(x)\nx = Dense(4, activation=\"relu\")(x)\nkeras.layers.BatchNormalization()(x)\nx = Dropout(0.05)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=[DMLP.input, cnn.input], outputs=x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = keras.optimizers.SGD()\nmodel.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[keras.metrics.BinaryAccuracy()])\n\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the input data to numpy arrays\nX_train = np.array(X_train)\nX_test = np.array(X_test)\nX_val = np.array(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# Convert the labels to numerical values\nencoder = LabelEncoder()\n\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.transform(y_test)\ny_val= encoder.transform(y_val)\nfrom tensorflow.keras.utils import to_categorical\n\n# Convert the labels to one-hot-encoding\n#distinct & model input requirement\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_val = to_categorical(y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images_norm = X_train.astype('float32')\ntest_images_norm = X_test.astype('float32')\nval_images_norm = X_val.astype('float32')\n# normalize to the range 0-1\ntrain_images_norm /= 255.0\ntest_images_norm /= 255.0\nval_images_norm /= 255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train[:, 0]\ny_val = y_val[:, 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\n# Define the function to optimize\ndef optimize_model(learning_rate,batch_size):\n    cb = [\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.1,\n        patience=3,\n        mode='auto',\n        min_delta=0.0002,\n        cooldown=5,\n        min_lr=10e-8,\n        verbose=1,\n    )\n]\n    \n    # Compile the model with the given learning rate and batch size\n    opt = keras.optimizers.SGD(learning_rate)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])\n    # dataset_label = tf.data.Dataset.from_tensor_slices(y_train)\n    from keras.callbacks import ModelCheckpoint\n\n    # Create a ModelCheckpoint callback to save the weights of the best model\n    checkpoint = ModelCheckpoint('/kaggle/working/best_model_weights.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True, mode='max', verbose=1)\n\n\n    # fit model\n    early_stopping = EarlyStopping(monitor='val_binary_accuracy', patience=10,restore_best_weights=True)\n\n    history = model.fit(x=[train_extr_features, train_images_norm],y=y_train,epochs = 100, steps_per_epoch=200,validation_data=([val_extr_features,val_images_norm],y_val),callbacks=[cb,early_stopping,checkpoint])\n    # Get the validation accuracy\n    accuracy = history.history['val_binary_accuracy'][-1]\n    \n    # Return the negative accuracy (since we want to maximize the accuracy)\n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5)\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\ncb = [\n    ReduceLROnPlateau(\n        monitor='val_binary_accuracy',\n        factor=0.1,\n        patience=3,\n        mode='auto',\n        min_delta=0.0002,\n        cooldown=5,\n        min_lr=10e-10,\n        verbose=1,\n    )\n]\n    \n# dataset_inputs = tf.data.Dataset.from_tensor_slices((train_extr_features, train_images_norm))\n# y_train = y_train[:, 0]\n# y_val = y_val[:, 0]\n\n# dataset_label = tf.data.Dataset.from_tensor_slices(y_train)\nfrom keras.callbacks import ModelCheckpoint\n\n# Create a ModelCheckpoint callback to save the weights of the best model\ncheckpoint = ModelCheckpoint('/kaggle/working/best_model_weights.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True, mode='max', verbose=1)\n\n\n# fit model\nearly_stopping = EarlyStopping(monitor='val_binary_accuracy', patience=10,restore_best_weights=True)\n\nhistory = model.fit(x=[train_extr_features, train_images_norm],y=y_train,epochs = 100, steps_per_epoch=200,validation_data=([val_extr_features,val_images_norm],y_val),callbacks=[cb,early_stopping,checkpoint])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\n\n# # Create a new instance of the model architecture\n# model = Model(inputs=[DMLP.input, cnn.input], outputs=x)\n# # Load the saved weights into the model\n# model.load_weights('best_model_weights.h5')\n\n\nscore = model.evaluate([val_extr_features,val_images_norm],y=y_val, batch_size=BATCH_SIZE, steps=200 )\nprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Manual Testing\n","metadata":{}},{"cell_type":"code","source":"import os\n\nSIZE = 256\nBATCH_SIZE = 15\nTARGET_SIZE = (SIZE,SIZE)\n# Set the directory path where your images are stored\ndir_path = '/kaggle/input/test-iamge/For Testing/Natural/Anime'\n\n\nNatural_images_Anime =[]\n\nfor img in os.listdir(os.path.join(dir_path)):\n    # Open the image\n    try: \n        img = dir_path + \"/\" + img\n        print(img)\n        image = cv2.imread(img, 3)\n        image = cv2.resize(image, TARGET_SIZE)\n        # Append the image to the images list\n        image = np.array(image)\n        Natural_images_Anime.append(image)\n    except:\n        pass\n        \nSYN_images_MIDJOURNEY =[]\n\ndir_path = '/kaggle/input/test-iamge/For Testing/Synthetic/test images/Midjourney'\n\nfor img in os.listdir(os.path.join(dir_path)):\n    # Open the image\n    try: \n        img = dir_path + \"/\" + img\n        print(img)\n        image = cv2.imread(img, 3)\n        image = cv2.resize(image, TARGET_SIZE)\n        # Append the image to the images list\n        image = np.array(image)\n        SYN_images_MIDJOURNEY.append(image)\n    except:\n        pass            ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For manual testing\nNatural_extr_Anime_features= feature_extractor(Natural_images_Anime)\nSYN_extr_MID_features = feature_extractor(SYN_images_MIDJOURNEY)\nSYN_images_MIDJOURNEY = np.array(SYN_images_MIDJOURNEY)\nNatural_images_Anime = np.array(Natural_images_Anime)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for further testing\nFurtherTesting_images_norm = Natural_images_Anime.astype('float32')\nFurtherTesting_images_norm/=255\nFurtherTesting_images_norm_SYN_MID = SYN_images_MIDJOURNEY.astype('float32')\nFurtherTesting_images_norm_SYN_MID/=255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir= \"/kaggle/input/test-iamge/For Testing/Natural\"\ndata_dir = pathlib.Path(data_dir)\n\ngenerated = list(data_dir.glob('Anime/*'))\nPIL.Image.open(str(generated[0]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\n\nimage = [Natural_extr_Anime_features,FurtherTesting_images_norm]\npred=model.predict(image)\n\nfor i in pred:\n    if i > 0.5:\n        print('Natural')\n    else:\n        print('Synthetic')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir= \"/kaggle/input/test-iamge/For Testing/Synthetic/test images/\"\ndata_dir = pathlib.Path(data_dir)\n\ngenerated = list(data_dir.glob('Midjourney/*'))\nPIL.Image.open(str(generated[3]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport cv2\n# SYN_extr_MID_features = feature_extractor(SYN_images_MIDJOURNEY)\n# SYN_images_MIDJOURNEY = np.array(SYN_images_MIDJOURNEY)\n\nimage = [SYN_extr_MID_features,FurtherTesting_images_norm_SYN_MID]\npred=model.predict(image)\nfor i in pred:\n    if i > 0.5:\n        print('Natural')\n    else:\n        print('Synthetic')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfeatures = model.predict([train_extr_features, train_images_norm])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features\nthreshold = 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the CNN model to extract features from the input data\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n#features = model.predict([train_extr_features, train_images_norm])\n\n# Build the XGBoost model to classify the input data based on the features extracted by the CNN model\nxgb_model = xgb.XGBClassifier()\nxgb_model.fit(features, y_train)\ntest_features = model.predict([val_extr_features,val_images_norm])\ny_pred = xgb_model.predict(test_features)\ny_pred_classes = np.zeros_like(y_pred, dtype=int)\ny_pred_classes[y_pred > threshold] = 1\naccuracy = accuracy_score(y_val, y_pred_classes)\nprint(f'Test accuracy: {accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nada_model = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=10, min_samples_split=5, min_samples_leaf=2),\n    n_estimators=50\n)\n\nada_model.fit(features, y_train)\n\n# Evaluate the XGBoost model on the test data\ntest_features = model.predict([val_extr_features,val_images_norm])\ny_pred = ada_model.predict(test_features)\ny_pred_classes1 = np.zeros_like(y_pred, dtype=int)\ny_pred_classes1[y_pred > threshold] = 1\n\naccuracy1 = accuracy_score(y_val, y_pred_classes1)\nprint(f'Test accuracy: {accuracy1}')\nprint(classification_report(y_val, y_pred_classes1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\n\n# Get the decision tree from the AdaBoostClassifier\ntree_model = ada_model.estimators_[0]\n\n# Plot the decision tree\nplt.figure(figsize=(20,20))\nplot_tree(tree_model, filled=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(40, 40))\nxgb.plot_tree(xgb_model, num_trees=0, ax=ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the Bayesian optimization object\nbounds = {'learning_rate': (1e-10,1e-4), 'batch_size': (16,32)}\nbo = BayesianOptimization(optimize_model,bounds)\nbo.maximize(init_points=5, n_iter=10)\n\n# Print the best hyperparameters\nprint(\"Best hyperparameters:\", bo.max)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2\n\n# for i in range(5):\n#     image=cv2.imread(str(generated[i]))\n#     image_resized= cv2.resize(image, (256,256))\n#     image=np.expand_dims(image_resized,axis=0)\n#     pred=model.predict(image)\n#     class_names= [\"Natural\",\"Synthetic\"]\n#     output_class=class_names[np.argmax(pred)]\n#     print(\"The predicted class is\", output_class)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow import lite\n\n# # Convert the model to TFLite format\n# converter = lite.TFLiteConverter.from_keras_model(model)\n# tflite_model = converter.convert()\n\n# # Save the TFLite model\n# with open(\"model256.tflite\", \"wb\") as f:\n#     f.write(tflite_model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import mean_squared_error\n\ny_pred = model.predict([val_extr_features,val_images_norm])\n# Define a threshold probability value\nthreshold = 0.5\n\n# Convert probabilities to class labels\ny_pred_classes = np.zeros_like(y_pred, dtype=int)\ny_pred_classes[y_pred > threshold] = 1\n\nscore1 = accuracy_score(y_val,y_pred_classes)\nscore2 = precision_score(y_val,y_pred_classes)\nscore3= recall_score(y_val,y_pred_classes)\nprint(\"\\n\")\nprint(\"Accuracy is \",round(score1*100,2),\"%\")\nprint(\"Precision is \",round(score2,2))\nprint(\"Recall is \",round(score3,2))\nprint('F1 Score:',f1_score(y_val, y_pred_classes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = [\"Natural\",\"Synthetic\"]\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\ndef show_confusion_matrix(confusion_matrix):\n  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n  plt.ylabel('True class')\n  plt.xlabel('Predicted class');\n\ncm = confusion_matrix(y_val, y_pred_classes)\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\nshow_confusion_matrix(df_cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_val, y_pred_classes, target_names=class_names))\n# Accuracy, Precision and Recall","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\n# Generate predictions\n\n# Convert predictions to binary labels\n\n\n# Compute false positive rate, true positive rate, and thresholds\nfpr, tpr, thresholds = roc_curve(y_val, y_pred_classes)\n\n# Compute area under the curve\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}